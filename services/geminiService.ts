
import { GoogleGenAI, Type, Modality } from "@google/genai";
import { SceneOutput } from '../types';

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const schema = {
  type: Type.OBJECT,
  properties: {
    title: { 
      type: Type.STRING,
      description: "A creative, short title for the scene."
    },
    image_prompt: { 
      type: Type.STRING,
      description: "The detailed image description for an AI image generator."
    },
    video_prompt: { 
      type: Type.STRING,
      description: "The detailed video prompt for an AI image-to-video generator."
    },
  },
  required: ['title', 'image_prompt', 'video_prompt'],
};

export const generateScenePrompts = async (idea: string): Promise<SceneOutput> => {
  const prompt = `
    Generate a cinematic anime scene based on the following idea: "${idea}"

    For this idea, generate two distinct outputs:

    1.  **Image Description (for an AI image generator like Nano Banana):**
        - Style: high-quality anime art, cinematic lighting, soft shading, dynamic composition.
        - Describe the full scene in detail, including character appearance (gender, outfit, expression, pose, motion hint), background (e.g., city, forest) with anime-style lighting, emotion, time of day, and camera angle.
        - The description must reflect the core concept: daily life x dance x anime vibes and action.

    2.  **Video Prompt (for an AI image-to-video generator like Grok AI):**
        - Duration: 20-35 seconds.
        - Describe camera movement (zoom, rotation, panning) and character movement/dance with film-style wording (e.g., "slow zoom-in," "dynamic tracking shot," "fast camera rotation").
        - Maintain an anime movie feel with expressive movement, emotional pacing, and clear action energy.

    Return the result in a single, valid JSON object that adheres to the provided schema.
  `;

  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-pro",
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: schema,
        temperature: 0.8,
      },
    });

    const jsonText = response.text.trim();
    const parsedResult: SceneOutput = JSON.parse(jsonText);
    return parsedResult;
  } catch (error) {
    console.error("Error generating scene prompts:", error);
    throw new Error("Failed to generate content from the AI. Please try again.");
  }
};

export const generateImageWithReference = async (prompt: string, base64Image: string, mimeType: string): Promise<string> => {
  try {
    const imagePart = {
      inlineData: {
        data: base64Image.split(',')[1], // Remove the data URI prefix
        mimeType: mimeType,
      },
    };

    const textPart = {
      text: `Using the provided reference image for the character, generate a new image based on this scene: ${prompt}`,
    };
    
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [imagePart, textPart] },
      config: {
        responseModalities: [Modality.IMAGE],
      },
    });

    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData) {
        return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
      }
    }
    
    throw new Error("No image was generated by the model.");

  } catch (error) {
    console.error("Error generating image with reference:", error);
    throw new Error("Failed to generate the image. Please check the console for details.");
  }
};
